{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from functools import partial\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "from dataclasses import dataclass\n",
    "from mpi4py import MPI\n",
    "from repast4py import context as ctx\n",
    "from repast4py import core, random, schedule, logging, parameters\n",
    "from repast4py.network import write_network, read_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of agents (nodes)\n",
    "num_agents = 20\n",
    "\n",
    "# Define the probability for edge creation (choose a value between 0 and 1)\n",
    "# Note: Adjust p to get the desired graph density.\n",
    "p = 0.05\n",
    "\n",
    "# Create the random graph\n",
    "G1 = nx.erdos_renyi_graph(n=num_agents, p=p)\n",
    "G2 = nx.erdos_renyi_graph(n=num_agents, p=p)\n",
    "G3 = nx.erdos_renyi_graph(n=num_agents, p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_network(G1, 'rumor_network', 'layer1.txt', 3)\n",
    "write_network(G2, 'rumor_network', 'layer2.txt', 3)\n",
    "write_network(G3, 'rumor_network', 'layer3.txt', 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def parse_and_update_network_files(file_paths):\n",
    "        node_info = {}\n",
    "        agents = defaultdict(lambda: defaultdict(dict))\n",
    "        all_nodes = set()\n",
    "\n",
    "        for layer_index, file_path in enumerate(file_paths):\n",
    "            with open(file_path, 'r') as f:\n",
    "                lines = f.read().splitlines()\n",
    "\n",
    "            if not lines:\n",
    "                continue\n",
    "\n",
    "            header = lines[0].strip().split()\n",
    "            if len(header) < 2:\n",
    "                continue\n",
    "            directed = header[1] == '1'\n",
    "\n",
    "            node_lines, edge_lines, found_edges = [], [], False\n",
    "\n",
    "            for line in lines[1:]:\n",
    "                if line.strip() == 'EDGES':\n",
    "                    found_edges = True\n",
    "                    continue\n",
    "                if not found_edges and layer_index == 0:\n",
    "                    node_lines.append(line.strip())\n",
    "                elif found_edges:\n",
    "                    edge_lines.append(line.strip())\n",
    "\n",
    "            if layer_index == 0:\n",
    "                for node_line in node_lines:\n",
    "                    parts = node_line.split()\n",
    "                    if len(parts) < 3:\n",
    "                        continue\n",
    "                    node_id, agent_type, rank = int(parts[0]), int(parts[1]), int(parts[2])\n",
    "                    node_info[node_id] = (node_id, agent_type, rank)\n",
    "                    all_nodes.add(node_id)\n",
    "\n",
    "            for edge_line in edge_lines:\n",
    "                parts = edge_line.split(' ', 2)\n",
    "                if len(parts) < 2:\n",
    "                    continue\n",
    "                u_id, v_id = int(parts[0]), int(parts[1])\n",
    "                if u_id not in node_info or v_id not in node_info:\n",
    "                    continue\n",
    "                u_tuple, v_tuple = node_info[u_id], node_info[v_id]\n",
    "                attrs = json.loads(parts[2]) if len(parts) == 3 else {}\n",
    "                weight = attrs.get('weight', 1.0)\n",
    "                agents[u_tuple][layer_index][v_tuple] = weight\n",
    "                if not directed:\n",
    "                    agents[v_tuple][layer_index][u_tuple] = weight\n",
    "\n",
    "        result = []\n",
    "        for node_id in sorted(all_nodes):\n",
    "            uid_tuple = node_info[node_id]\n",
    "            agent_dict = {layer: {str(k): v for k, v in agents[uid_tuple].get(layer, {}).items()} for layer in range(len(file_paths))}\n",
    "            result.append(agent_dict)\n",
    "\n",
    "        with open(file_paths[0], 'r') as f:\n",
    "            lines = f.read().splitlines()\n",
    "\n",
    "        updated_lines, node_index, found_edges = [], 0, False\n",
    "\n",
    "        for line in lines:\n",
    "            if line.strip() == 'EDGES':\n",
    "                found_edges = True\n",
    "            if not found_edges and line.strip():\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 3:\n",
    "                    shadow_data = json.dumps({\"shadow\": result[node_index]})\n",
    "                    updated_lines.append(f\"{parts[0]} {parts[1]} {parts[2]} {shadow_data}\")\n",
    "                    node_index += 1\n",
    "                else:\n",
    "                    updated_lines.append(line)\n",
    "            else:\n",
    "                updated_lines.append(line)\n",
    "\n",
    "        with open(file_paths[0], 'w') as f:\n",
    "            f.write('\\n'.join(updated_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_and_update_network_files(['layer1.txt', 'layer2.txt', 'layer3.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "\n",
    "\n",
    "class RumorAgent(core.Agent):\n",
    "\n",
    "    def __init__(self, nid: int, agent_type: int, rank: int, received_rumor=False, shadow=None):\n",
    "        super().__init__(nid, agent_type, rank)\n",
    "        self.received_rumor = received_rumor\n",
    "        self.shadow = shadow or {}\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\"Saves the state of this agent as tuple.\n",
    "\n",
    "        A non-ghost agent will save its state using this\n",
    "        method, and any ghost agents of this agent will\n",
    "        be updated with that data (self.received_rumor).\n",
    "\n",
    "        Returns:\n",
    "            The agent's state\n",
    "        \"\"\"\n",
    "        return (self.uid, self.received_rumor, self.shadow)\n",
    "\n",
    "    def update(self, data: bool):\n",
    "        \"\"\"Updates the state of this agent when it is a ghost\n",
    "        agent on some rank other than its local one.\n",
    "\n",
    "        Args:\n",
    "            data: the new agent state (received_rumor)\n",
    "        \"\"\"\n",
    "        received_rumor, shadow_data = data[0], data[1]\n",
    "\n",
    "        if not self.received_rumor and received_rumor:\n",
    "            # only update if the received rumor state\n",
    "            # has changed from false to true\n",
    "            model.rumor_spreaders.append(self)\n",
    "            self.received_rumor = received_rumor\n",
    "        \n",
    "        self.shadow = shadow_data\n",
    "\n",
    "\n",
    "def create_rumor_agent(nid, agent_type, rank, **kwargs):\n",
    "    shadow = kwargs.get('shadow', {})\n",
    "    return RumorAgent(nid, agent_type, rank, shadow=shadow)\n",
    "\n",
    "\n",
    "def restore_agent(agent_data):\n",
    "    uid = agent_data[0]\n",
    "    received_rumor = agent_data[1]\n",
    "    shadow = agent_data[2] if len(agent_data) > 2 else {}  # Handle cases where shadow might not be saved\n",
    "    return RumorAgent(uid[0], uid[1], uid[2], received_rumor, shadow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class RumorCounts:\n",
    "    total_rumor_spreaders: int\n",
    "    new_rumor_spreaders: int\n",
    "\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, comm, params):\n",
    "        self.runner = schedule.init_schedule_runner(comm)\n",
    "        self.runner.schedule_stop(params['stop.at'])\n",
    "        self.runner.schedule_end_event(self.at_end)\n",
    "\n",
    "        fpath = params['network_file']\n",
    "        self.context = ctx.SharedContext(comm)\n",
    "        read_network(fpath, self.context, create_rumor_agent, restore_agent)\n",
    "        self.net = self.context.get_projection('rumor_network')\n",
    "\n",
    "        self.rumor_spreaders = []\n",
    "        self.rank = comm.Get_rank()\n",
    "        self._seed_rumor(params['initial_rumor_count'], comm)\n",
    "\n",
    "        rumored_count = len(self.rumor_spreaders)\n",
    "        self.counts = RumorCounts(rumored_count, rumored_count)\n",
    "        loggers = logging.create_loggers(self.counts, op=MPI.SUM, rank=self.rank)\n",
    "        self.data_set = logging.ReducingDataSet(loggers, comm, params['counts_file'])\n",
    "        self.data_set.log(0)\n",
    "\n",
    "        self.rumor_prob = params['rumor_probability']\n",
    "\n",
    "        # Schedule layer-specific steps\n",
    "        layer_schedules = params['layer_schedules']\n",
    "        for layer_id, schedule_config in enumerate(layer_schedules):\n",
    "            start = schedule_config['start']\n",
    "            interval = schedule_config['interval']\n",
    "            self.runner.schedule_repeating_event(start, interval, partial(self.new_step, layer=layer_id))\n",
    "\n",
    "    def _seed_rumor(self, init_rumor_count: int, comm):\n",
    "        world_size = comm.Get_size()\n",
    "        rumor_counts = np.zeros(world_size, dtype=np.int32)\n",
    "        if self.rank == 0:\n",
    "            rng = random.default_rng()\n",
    "            for _ in range(init_rumor_count):\n",
    "                idx = rng.integers(0, high=world_size)\n",
    "                rumor_counts[idx] += 1\n",
    "\n",
    "        rumor_count = np.empty(1, dtype=np.int32)\n",
    "        comm.Scatter(rumor_counts, rumor_count, root=0)\n",
    "\n",
    "        for agent in self.context.agents(count=rumor_count[0], shuffle=True):\n",
    "            agent.received_rumor = True\n",
    "            self.rumor_spreaders.append(agent)\n",
    "\n",
    "    def at_end(self):\n",
    "        self.data_set.close()\n",
    "\n",
    "    def new_step(self, layer):\n",
    "        new_rumor_spreaders = []\n",
    "        rng = random.default_rng()\n",
    "        for agent in self.rumor_spreaders:\n",
    "            if layer not in agent.shadow:\n",
    "                continue\n",
    "            layer_edges = agent.shadow[layer]\n",
    "            for key_str in layer_edges:\n",
    "                # Parse the neighbor's UID from the string key\n",
    "                try:\n",
    "                    ngh_uid = ast.literal_eval(key_str)\n",
    "                except:\n",
    "                    continue  # Skip invalid keys\n",
    "                ngh_agent = self.context.get_agent(ngh_uid)\n",
    "                if ngh_agent is None:\n",
    "                    continue  # Neighbor not found (shouldn't happen if network is correct)\n",
    "                # Only spread to local agents that haven't received the rumor\n",
    "                if ngh_agent.local_rank == self.rank and not ngh_agent.received_rumor:\n",
    "                    if rng.uniform() <= self.rumor_prob:\n",
    "                        ngh_agent.received_rumor = True\n",
    "                        new_rumor_spreaders.append(ngh_agent)\n",
    "        # Update the list of rumor spreaders with new local agents\n",
    "        self.rumor_spreaders += new_rumor_spreaders\n",
    "        # Update counts\n",
    "        self.counts.new_rumor_spreaders = len(new_rumor_spreaders)\n",
    "        self.counts.total_rumor_spreaders += self.counts.new_rumor_spreaders\n",
    "        self.data_set.log(self.runner.schedule.tick)\n",
    "        # Synchronize agents across ranks\n",
    "        self.context.synchronize(restore_agent)\n",
    "\n",
    "    def start(self):\n",
    "        self.runner.execute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
