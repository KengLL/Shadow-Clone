{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from functools import partial\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from mpi4py import MPI\n",
    "from repast4py import context as ctx\n",
    "from repast4py import core, random, schedule, logging, parameters\n",
    "from repast4py.network import write_network, read_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of agents (nodes)\n",
    "num_agents = 1000\n",
    "\n",
    "# Define the probability for edge creation (choose a value between 0 and 1)\n",
    "# Note: Adjust p to get the desired graph density.\n",
    "p = 0.01\n",
    "\n",
    "# Create the random graph\n",
    "G1 = nx.erdos_renyi_graph(n=num_agents, p=p)\n",
    "G2 = nx.erdos_renyi_graph(n=num_agents, p=p)\n",
    "path1, path2 = 'networks/layer1.txt', 'networks/layer2.txt'\n",
    "write_network(G1, 'rumor_network', path1, 1)\n",
    "write_network(G2, 'rumor_network', path2, 1)\n",
    "# G1 = nx.erdos_renyi_graph(n=num_agents//2, p=p)\n",
    "# G2 = nx.erdos_renyi_graph(n=num_agents//2, p=p)\n",
    "# write_network(G1, 'rumor_network', path1, 1)\n",
    "# write_network(G2, 'rumor_network', path2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create first network: 20 nodes with last 10 interconnected\n",
    "G1 = nx.Graph()\n",
    "G1.add_nodes_from(range(num_agents))\n",
    "\n",
    "# Interconnect last 10 nodes (10-19)\n",
    "edges_layer1 = [(i, j) for i in range(10, 20) for j in range(i + 1, 20)]\n",
    "G1.add_edges_from(edges_layer1)\n",
    "\n",
    "# Create second network: Erdős-Rényi graph with first 10 nodes\n",
    "G2 = nx.erdos_renyi_graph(n=num_agents // 2, p=p)\n",
    "write_network(G1, 'rumor_network', path1, 1)\n",
    "write_network(G2, 'rumor_network', path2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated network data has been written to: networks/layer1.txt_multi\n"
     ]
    }
   ],
   "source": [
    "from network import *\n",
    "parse_and_write_network_files([path1, path2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Parse network files to dictionaries\n",
    "edges = parse_to_dictionaries([path1, path2]) \n",
    "# Compress dictionaries to string (Dictionaries -> String -> Compressed String)\n",
    "compressed_edges = compress_dictionaries_to_string(edges)\n",
    "# Decompress compressed string to dictionaries\n",
    "decompressed_edges = decompress_string_to_dictionaries(compressed_edges) # Decompressed list of dictionaries\n",
    "print(edges == decompressed_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "\n",
    "class RumorAgent(core.Agent):\n",
    "\n",
    "    def __init__(self, nid: int, agent_type: int, rank: int, received_rumor=False, shadow=None):\n",
    "        super().__init__(nid, agent_type, rank)\n",
    "        self.received_rumor = received_rumor\n",
    "        self.shadow = shadow or {}\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\"Saves the state of this agent as tuple.\n",
    "\n",
    "        A non-ghost agent will save its state using this\n",
    "        method, and any ghost agents of this agent will\n",
    "        be updated with that data (self.received_rumor).\n",
    "\n",
    "        Returns:\n",
    "            The agent's state\n",
    "        \"\"\"\n",
    "        return (self.uid, self.received_rumor, self.shadow)\n",
    "\n",
    "    def update(self, data: bool):\n",
    "        \"\"\"Updates the state of this agent when it is a ghost\n",
    "        agent on some rank other than its local one.\n",
    "\n",
    "        Args:\n",
    "            data: the new agent state (received_rumor)\n",
    "        \"\"\"\n",
    "        received_rumor, shadow_data = data[0], data[1]\n",
    "\n",
    "        if not self.received_rumor and received_rumor:\n",
    "            # only update if the received rumor state\n",
    "            # has changed from false to true\n",
    "            model.rumor_spreaders.append(self)\n",
    "            self.received_rumor = received_rumor\n",
    "        \n",
    "        self.shadow = shadow_data\n",
    "\n",
    "\n",
    "def create_rumor_agent(nid, agent_type, rank, **kwargs):\n",
    "    shadow_data = {}\n",
    "    if 'data' in kwargs:  # New compressed format\n",
    "        shadow_data = decompress_and_convert_shadow_data(kwargs['data'])\n",
    "    return RumorAgent(nid, agent_type, rank, received_rumor=None, shadow=shadow_data)\n",
    "\n",
    "\n",
    "def restore_agent(agent_data):\n",
    "    uid = agent_data[0]\n",
    "    received_rumor = agent_data[1]\n",
    "    shadow = agent_data[2] if len(agent_data) > 2 else {}  # Handle cases where shadow might not be saved\n",
    "    return RumorAgent(uid[0], uid[1], uid[2], received_rumor, shadow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class RumorCounts:\n",
    "    total_rumor_spreaders: int\n",
    "    new_rumor_spreaders: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, comm, params):\n",
    "        self.runner = schedule.init_schedule_runner(comm)\n",
    "        self.runner.schedule_stop(params['stop.at'])\n",
    "        self.runner.schedule_end_event(self.at_end)\n",
    "\n",
    "        fpath = params['network_file']\n",
    "        self.context = ctx.SharedContext(comm)\n",
    "        read_network(fpath, self.context, create_rumor_agent, restore_agent)\n",
    "        self.net = self.context.get_projection('rumor_network')\n",
    "\n",
    "        self.rumor_spreaders = []\n",
    "        self.rank = comm.Get_rank()\n",
    "        self._seed_rumor(params['initial_rumor_count'], comm)\n",
    "\n",
    "        rumored_count = len(self.rumor_spreaders)\n",
    "        self.counts = RumorCounts(rumored_count, rumored_count)\n",
    "        loggers = logging.create_loggers(self.counts, op=MPI.SUM, rank=self.rank)\n",
    "        self.data_set = logging.ReducingDataSet(loggers, comm, params['counts_file'])\n",
    "        self.data_set.log(0)\n",
    "\n",
    "        self.rumor_prob = params['rumor_probability']\n",
    "\n",
    "        # Schedule layer-specific steps\n",
    "        layer_schedules = params['layer_schedules']\n",
    "        for layer_id, schedule_config in enumerate(layer_schedules):\n",
    "            start = schedule_config['start']\n",
    "            interval = schedule_config['interval']\n",
    "            self.runner.schedule_repeating_event(start, interval, partial(self.new_step, layer=layer_id))\n",
    "        \n",
    "        for agent in self.context.agents():\n",
    "           print(agent.uid, agent.shadow)\n",
    "            \n",
    "    def _seed_rumor(self, init_rumor_count: int, comm):\n",
    "        world_size = comm.Get_size()\n",
    "        rumor_counts = np.zeros(world_size, dtype=np.int32)\n",
    "        if self.rank == 0:\n",
    "            rng = np.random.default_rng()\n",
    "            for _ in range(init_rumor_count):\n",
    "                idx = rng.integers(0, high=world_size)\n",
    "                rumor_counts[idx] += 1\n",
    "\n",
    "        rumor_count = np.empty(1, dtype=np.int32)\n",
    "        comm.Scatter(rumor_counts, rumor_count, root=0)\n",
    "\n",
    "        for agent in self.context.agents(count=rumor_count[0], shuffle=True):\n",
    "            agent.received_rumor = True\n",
    "            self.rumor_spreaders.append(agent)\n",
    "\n",
    "    def at_end(self):\n",
    "        self.data_set.close()\n",
    "\n",
    "    def new_step(self, layer):\n",
    "        new_rumor_spreaders = []\n",
    "        rng = np.random.default_rng()\n",
    "        for agent in self.rumor_spreaders:\n",
    "            # Agent does not have outgoing edges in this layer\n",
    "            if layer not in agent.shadow.keys():\n",
    "                continue\n",
    "            ngh_tuples = agent.shadow[layer].keys()\n",
    "            for ngh_tuple in ngh_tuples:\n",
    "                ngh_agent = self.context.agent(ngh_tuple)\n",
    "                if ngh_agent is None:\n",
    "                    continue  # Neighbor not found (shouldn't happen if network is correct)\n",
    "                # Only spread to local agents that haven't received the rumor\n",
    "                if ngh_agent.local_rank == self.rank and not ngh_agent.received_rumor:\n",
    "                    if rng.uniform() <= self.rumor_prob:\n",
    "                        ngh_agent.received_rumor = True\n",
    "                        new_rumor_spreaders.append(ngh_agent)\n",
    "        # Update the list of rumor spreaders with new local agents\n",
    "        self.rumor_spreaders += new_rumor_spreaders\n",
    "        # Update counts\n",
    "        self.counts.new_rumor_spreaders = len(new_rumor_spreaders)\n",
    "        self.counts.total_rumor_spreaders += self.counts.new_rumor_spreaders\n",
    "        self.data_set.log(self.runner.schedule.tick)\n",
    "        # Synchronize agents across ranks\n",
    "        self.context.synchronize(restore_agent)\n",
    "\n",
    "    def start(self):\n",
    "        self.runner.execute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 0) {0: {}, 1: {}}\n",
      "(1, 0, 0) {0: {}, 1: {}}\n",
      "(2, 0, 0) {0: {}, 1: {}}\n",
      "(3, 0, 0) {0: {}, 1: {}}\n",
      "(4, 0, 0) {0: {}, 1: {}}\n",
      "(5, 0, 0) {0: {}, 1: {}}\n",
      "(6, 0, 0) {0: {}, 1: {}}\n",
      "(7, 0, 0) {0: {}, 1: {}}\n",
      "(8, 0, 0) {0: {}, 1: {}}\n",
      "(9, 0, 0) {0: {}, 1: {}}\n",
      "(10, 0, 0) {0: {(11, 0, 0): 1.0, (12, 0, 0): 1.0, (13, 0, 0): 1.0, (14, 0, 0): 1.0, (15, 0, 0): 1.0, (16, 0, 0): 1.0, (17, 0, 0): 1.0, (18, 0, 0): 1.0, (19, 0, 0): 1.0}, 1: {}}\n",
      "(11, 0, 0) {0: {(10, 0, 0): 1.0, (12, 0, 0): 1.0, (13, 0, 0): 1.0, (14, 0, 0): 1.0, (15, 0, 0): 1.0, (16, 0, 0): 1.0, (17, 0, 0): 1.0, (18, 0, 0): 1.0, (19, 0, 0): 1.0}, 1: {}}\n",
      "(12, 0, 0) {0: {(10, 0, 0): 1.0, (11, 0, 0): 1.0, (13, 0, 0): 1.0, (14, 0, 0): 1.0, (15, 0, 0): 1.0, (16, 0, 0): 1.0, (17, 0, 0): 1.0, (18, 0, 0): 1.0, (19, 0, 0): 1.0}, 1: {}}\n",
      "(13, 0, 0) {0: {(10, 0, 0): 1.0, (11, 0, 0): 1.0, (12, 0, 0): 1.0, (14, 0, 0): 1.0, (15, 0, 0): 1.0, (16, 0, 0): 1.0, (17, 0, 0): 1.0, (18, 0, 0): 1.0, (19, 0, 0): 1.0}, 1: {}}\n",
      "(14, 0, 0) {0: {(10, 0, 0): 1.0, (11, 0, 0): 1.0, (12, 0, 0): 1.0, (13, 0, 0): 1.0, (15, 0, 0): 1.0, (16, 0, 0): 1.0, (17, 0, 0): 1.0, (18, 0, 0): 1.0, (19, 0, 0): 1.0}, 1: {}}\n",
      "(15, 0, 0) {0: {(10, 0, 0): 1.0, (11, 0, 0): 1.0, (12, 0, 0): 1.0, (13, 0, 0): 1.0, (14, 0, 0): 1.0, (16, 0, 0): 1.0, (17, 0, 0): 1.0, (18, 0, 0): 1.0, (19, 0, 0): 1.0}, 1: {}}\n",
      "(16, 0, 0) {0: {(10, 0, 0): 1.0, (11, 0, 0): 1.0, (12, 0, 0): 1.0, (13, 0, 0): 1.0, (14, 0, 0): 1.0, (15, 0, 0): 1.0, (17, 0, 0): 1.0, (18, 0, 0): 1.0, (19, 0, 0): 1.0}, 1: {}}\n",
      "(17, 0, 0) {0: {(10, 0, 0): 1.0, (11, 0, 0): 1.0, (12, 0, 0): 1.0, (13, 0, 0): 1.0, (14, 0, 0): 1.0, (15, 0, 0): 1.0, (16, 0, 0): 1.0, (18, 0, 0): 1.0, (19, 0, 0): 1.0}, 1: {}}\n",
      "(18, 0, 0) {0: {(10, 0, 0): 1.0, (11, 0, 0): 1.0, (12, 0, 0): 1.0, (13, 0, 0): 1.0, (14, 0, 0): 1.0, (15, 0, 0): 1.0, (16, 0, 0): 1.0, (17, 0, 0): 1.0, (19, 0, 0): 1.0}, 1: {}}\n",
      "(19, 0, 0) {0: {(10, 0, 0): 1.0, (11, 0, 0): 1.0, (12, 0, 0): 1.0, (13, 0, 0): 1.0, (14, 0, 0): 1.0, (15, 0, 0): 1.0, (16, 0, 0): 1.0, (17, 0, 0): 1.0, (18, 0, 0): 1.0}, 1: {}}\n"
     ]
    }
   ],
   "source": [
    "def run(params: Dict):\n",
    "    global model\n",
    "    model = Model(MPI.COMM_WORLD, params)\n",
    "    model.start()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    params = {\n",
    "        'layer_schedules': [\n",
    "            {'start': 0, 'interval': 1},\n",
    "            {'start': 0, 'interval': 2}\n",
    "        ],\n",
    "        'network_file': 'networks/layer1.txt_multi',\n",
    "        'initial_rumor_count': 15,\n",
    "        'stop.at': 100,\n",
    "        'rumor_probability': 1,\n",
    "        'counts_file': 'output/rumor_counts.csv'\n",
    "    }\n",
    "    run(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
